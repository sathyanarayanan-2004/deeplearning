{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502263b3",
   "metadata": {},
   "source": [
    "EX-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4113bb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume1.txt passing the screenning text in score of 3\n",
      "resume3.txt passing the screenning text in score of 3\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import string\n",
    "\n",
    "def preprocess_word(text):\n",
    "    text=text.lower()\n",
    "    text=text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens=text.split()\n",
    "    stopwords=set([\"a\",\"an\",\"in\",\"the\",\"on\",\"and\",\"is\",\"are\",\"was\",\"were\"])\n",
    "    tokens=[token for token in tokens if token not in stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def screen_resume(resume, job_requirements):\n",
    "    preprocessed_resume = preprocess_word(resume)\n",
    "    keyword_matches = 0\n",
    "    for keyword in job_requirements:\n",
    "        if re.search(r'\\b{}\\b'.format(keyword), preprocessed_resume, re.IGNORECASE):\n",
    "            keyword_matches += 1\n",
    "    return keyword_matches\n",
    "\n",
    "def main():\n",
    "    job_requirements=['python','machine learning','data analyst']\n",
    "    resumes=['resume1.txt','resume2.txt','resume3.txt']\n",
    "    for resume in resumes:\n",
    "        with open(resume,'r') as file:\n",
    "            resume_file=file.read()\n",
    "            score=screen_resume(resume_file,job_requirements)\n",
    "            \n",
    "            if score>=2:\n",
    "                print(f\"{resume} passing the screenning text in score of {score}\")\n",
    "if __name__==\"__main__\":\n",
    "    main()           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7601ae",
   "metadata": {},
   "source": [
    "EX-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45dc0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity:Apple Inc., Label:ORG\n",
      "Entity:Steve Jobs, Label:PERSON\n",
      "Entity:Steve Wozniak, Label:PERSON\n",
      "Entity:Ronald Wayne, Label:PERSON\n",
      "Entity:Cupertino, Label:GPE\n",
      "Entity:California, Label:GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def perform_ner(text):\n",
    "    nlp=spacy.load(\"en_core_web_sm\")\n",
    "    doc=nlp(text)\n",
    "    entities=[]\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text,ent.label_))\n",
    "    return entities\n",
    "\n",
    "def main():\n",
    "    text = \"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne. \" \\\n",
    "    \"It is headquartered in Cupertino, California.\"\n",
    "    entities=perform_ner(text)\n",
    "    for entity,label in entities:\n",
    "        print(f\"Entity:{entity}, Label:{label}\")\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b2e6b",
   "metadata": {},
   "source": [
    "Ex-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9593bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive statement\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "def perform_sentiment_analysis(text):\n",
    "    blob=TextBlob(text)\n",
    "    sentiment=blob.sentiment.polarity\n",
    "    return sentiment\n",
    "def main():\n",
    "    text=\"I love this movie!,It is fastinating\"\n",
    "    sentiment=perform_sentiment_analysis(text)\n",
    "    if sentiment>0:\n",
    "        print(\"positive statement\")\n",
    "    elif sentiment<0:\n",
    "        print(\"Negative statement\")\n",
    "    else:\n",
    "        print(\"Neutral statement\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79249eda",
   "metadata": {},
   "source": [
    "Ex-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5411e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versatile programming language known\n",
      "widely used\n",
      "web development\n",
      "data analysis\n",
      "artificial intelligence\n",
      "simplicity\n",
      "readability\n",
      "python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sathy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sathy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#rapid automatic keyword extraction\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "def perform_rake(text):\n",
    "    rake=Rake()\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    ranked_keyword=rake.get_ranked_phrases()\n",
    "    return ranked_keyword\n",
    "def main():\n",
    "    text = \"Python is a versatile programming language known for its simplicity and readability. \" \\\n",
    "           \"It is widely used in web development, data analysis, and artificial intelligence.\"\n",
    "    keywords=perform_rake(text)\n",
    "    for keyword in keywords:\n",
    "        print(keyword)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dfe3a9",
   "metadata": {},
   "source": [
    "Ex-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf66af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a sentence with misspelled words.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "def perform_spelling_correction(text):\n",
    "    blob=TextBlob(text)\n",
    "    corrected_text=blob.correct()\n",
    "    return corrected_text\n",
    "def main():\n",
    "    text = \"It is a sentense with misspelled wrds.\"\n",
    "    corrected_sentence=perform_spelling_correction(text)\n",
    "    print(corrected_sentence)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa61b8",
   "metadata": {},
   "source": [
    "Ex-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c801d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to eat apple and banana\n"
     ]
    }
   ],
   "source": [
    "from difflib import get_close_matches\n",
    "def build_autocorrect_model(words):\n",
    "    return{word.lower():word for word in words}\n",
    "\n",
    "def autocorrect_input(input_text,autocorrect_model):\n",
    "    corrected_text=[]\n",
    "    words=input_text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        corrected_word=autocorrect_model.get(word.lower())\n",
    "        if corrected_word:\n",
    "            corrected_text.append(corrected_word)\n",
    "        else:\n",
    "            closest_match=get_close_matches(word.lower(),autocorrect_model.keys(),n=1,cutoff=0.8)\n",
    "            if closest_match:\n",
    "                corrected_text.append(autocorrect_model[closest_match[0]])\n",
    "            else:\n",
    "                corrected_text.append(word)\n",
    "    return ' '.join(corrected_text)\n",
    "\n",
    "def main():\n",
    "    word_list = ['apple', 'banana', 'cat', 'dog', 'elephant', 'fish']\n",
    "    autocorrect_model=build_autocorrect_model(word_list)\n",
    "    input_text = \"I like to eat applle and bananana.\"\n",
    "    corrected_text=autocorrect_input(input_text,autocorrect_model)\n",
    "    print(corrected_text)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6df49",
   "metadata": {},
   "source": [
    "Ex-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "031d84e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.2.0\n",
      "    Uninstalling fsspec-2022.2.0:\n",
      "      Successfully uninstalled fsspec-2022.2.0\n",
      "Successfully installed fsspec-2024.5.0 huggingface-hub-0.23.2 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa14717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\sathy\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a0cefaf9f24781a0b81cb80a1da3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathy\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sathy\\.cache\\huggingface\\hub\\models--google-t5--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4a89d70ce34b9792d27bcc039ee645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef64e1d0c09425d8d9b673d3a268180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113223865f664398940cf13a96c80e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e23c62bdda4e72bf5577f5257b0741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "the term \"artificial intelligence\" is often used to describe machines that mimic \"cognitive\" functions that humans associate with the human mind . tasks considered to require \"intelligence\" are often removed from the definition of AI .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def summarize_text(text):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "def main():\n",
    "    with open('input.txt', 'r') as file:\n",
    "        text = file.read()\n",
    "    summary = summarize_text(text)\n",
    "    print(\"Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f8946",
   "metadata": {},
   "source": [
    "Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe2bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Movie Ticket Booking Chatbot!\n",
      "Which movie would you like to watch? anniyan\n",
      "How many tickets do you want to book? 3\n",
      "What showtime would you prefer (e.g., 7:00 PM)? 8:00 pm\n",
      "\n",
      "Please confirm your booking details:\n",
      "Movie: anniyan\n",
      "Number of tickets: 3\n",
      "Showtime: 8:00 pm\n",
      "Do you want to confirm the booking? (yes/no) yes\n",
      "\n",
      "Your booking is confirmed! Enjoy the movie!\n"
     ]
    }
   ],
   "source": [
    "def chatbot():\n",
    "    print(\"Welcome to the Movie Ticket Booking Chatbot!\")\n",
    "    \n",
    "    # Step 1: Greet the user and ask for the movie they want to watch\n",
    "    movie_name = input(\"Which movie would you like to watch? \")\n",
    "    \n",
    "    # Step 2: Ask for the number of tickets\n",
    "    while True:\n",
    "        try:\n",
    "            num_tickets = int(input(\"How many tickets do you want to book? \"))\n",
    "            if num_tickets <= 0:\n",
    "                print(\"Please enter a valid number of tickets.\")\n",
    "            else:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")\n",
    "    \n",
    "    # Step 3: Ask for the showtime\n",
    "    showtime = input(\"What showtime would you prefer (e.g., 7:00 PM)? \")\n",
    "    \n",
    "    # Step 4: Confirm the booking details\n",
    "    print(\"\\nPlease confirm your booking details:\")\n",
    "    print(f\"Movie: {movie_name}\")\n",
    "    print(f\"Number of tickets: {num_tickets}\")\n",
    "    print(f\"Showtime: {showtime}\")\n",
    "    \n",
    "    confirm = input(\"Do you want to confirm the booking? (yes/no) \")\n",
    "    \n",
    "    if confirm.lower() == 'yes':\n",
    "        print(\"\\nYour booking is confirmed! Enjoy the movie!\")\n",
    "    else:\n",
    "        print(\"\\nYour booking has been cancelled. Have a nice day!\")\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df38682",
   "metadata": {},
   "source": [
    "EX-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00a244ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\sathy\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: textblob in c:\\users\\sathy\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (61.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.27.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.64.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.11.3)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.4)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sathy\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.1)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy textblob\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fc93298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me PRON\n",
      "encanta VERB\n",
      "la DET\n",
      "comida NOUN\n",
      "mexicana ADJ\n",
      "y CCONJ\n",
      "el DET\n",
      "tequila PROPN\n",
      ". PUNCT\n",
      "Sentiment score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "text = \"Me encanta la comida mexicana y el tequila.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "sentiment_score = 0\n",
    "for sentence in doc.sents:\n",
    "    analysis = TextBlob(sentence.text)\n",
    "    sentiment_score += analysis.sentiment.polarity\n",
    "\n",
    "print(\"Sentiment score:\", sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05781f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
